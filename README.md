# ğŸ§  Stress Analyzer

**Stress Analyzer** is a machine learning project that analyzes human stress levels using **facial expressions** and **voice tone**.  
It can run in real-time through a webcam or use pre-recorded `.wav` / `.mp4` files for emotion recognition.

---

## ğŸš€ Features

- ğŸ¤ **Audio-based stress detection** (trained with the RAVDESS dataset)
- ğŸ‘ï¸ **Facial emotion recognition** using MediaPipe FaceMesh
- ğŸ§© **Random Forest model** trained on MFCC and facial landmark features
- ğŸ§  **3 stress levels detected:**
  ```bash
  0 â†’ Calm
  1 â†’ Neutral
  2 â†’ Stressed
  ```
- ğŸ› ï¸ Streamlit interface for real-time webcam visualization
- ğŸ“¦ Modular folder structure for extending to new data or models

---

## ğŸ—‚ï¸ Project Structure

```bash
stress-analyzer/
â”‚
â”œâ”€â”€ face_stress_analyzer/
â”‚   â”œâ”€â”€ app_live.py                # Streamlit live webcam app
â”‚   â”œâ”€â”€ extract_features.py        # Extract features (RAVDESS or custom)
â”‚   â”œâ”€â”€ train_model.py             # Train RandomForest model
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ face_stress_model.pkl  # Saved ML model
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/                   # Raw audio/video data
â”‚   â”‚   â””â”€â”€ processed/             # Extracted feature CSVs
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§® Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/asknnsinem/stress-analyzer.git
cd stress-analyzer
```

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ§  Model Training

### Extract features
```bash
cd face_stress_analyzer
python extract_features.py
```

### Train the model
```bash
python train_model.py
```

The trained model will be saved as:
```bash
models/face_stress_model.pkl
```

---

## ğŸ¥ Run Real-Time Detection (Webcam)
```bash
streamlit run app_live.py
```
Then open the URL (e.g. `http://localhost:8501`) in your browser.

---

## ğŸ§¾ Example Output

- Webcam feed with face landmarks visualized  
- Stress prediction (0â€“2) displayed live  
- Logs stored under `.streamlit` or `logs/` folder  

---

## âš™ï¸ Requirements

```bash
Python 3.10â€“3.11
TensorFlow 2.13+
MediaPipe 0.10.10+
OpenCV 4.12+
Scikit-learn 1.5+
Streamlit 1.51+
```

---

## ğŸ§  Dataset

The project uses the **RAVDESS** dataset for training:

[ğŸ§ Ryerson Audio-Visual Database of Emotional Speech and Song](https://zenodo.org/record/1188976)

You can also record your own samples and label them manually under:
```bash
data/raw/{calm, medium, stress}/
```

---

## ğŸ§‘â€ğŸ’» Future Improvements

- Add temporal (blink rate, heart rate) analysis
- Support multilingual voice stress detection
- Add fine-tuned CNN/LSTM models for improved accuracy

---

## ğŸ“„ License

This project is released under the **MIT License**.  
You are free to use, modify, and distribute with proper credit.

---

## â¤ï¸ Author

[@asknnsinem](https://github.com/asknnsinem)

**Real-time Stress Analysis using AI and Computer Vision**

