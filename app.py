import streamlit as st
import sounddevice as sd
import numpy as np
import pandas as pd
import joblib
import soundfile as sf
from python_speech_features import mfcc
import tempfile
import os

# ========================
# Model yÃ¼kleme
# ========================
@st.cache_resource
def load_model():
    model = joblib.load("models/stress_model.pkl")
    return model

model = load_model()

# ========================
# MFCC Ã§Ä±karÄ±m fonksiyonu
# ========================
def extract_features(audio, samplerate):
    if len(audio.shape) > 1:
        audio = np.mean(audio, axis=1)
    mfcc_feat = mfcc(audio, samplerate, numcep=20, nfilt=40, nfft=2048)
    mfcc_mean = np.mean(mfcc_feat, axis=0)
    return mfcc_mean.reshape(1, -1)

# ========================
# Streamlit ArayÃ¼zÃ¼
# ========================
st.set_page_config(page_title="ğŸ§ Stress Analyzer", page_icon="ğŸ™ï¸", layout="centered")

st.title("ğŸ§ Stress Analyzer")
st.write("Mikrofonla kÄ±sa bir ses kaydÄ± al ve modelin stres seviyeni tahmin etmesine izin ver.")

duration = st.slider("KayÄ±t sÃ¼resi (saniye)", 2, 10, 4)
if st.button("ğŸ™ï¸ KaydÄ± BaÅŸlat"):
    st.info("Kaydediliyor... KonuÅŸmaya baÅŸla ğŸ¤")
    fs = 16000  # Ã¶rnekleme hÄ±zÄ±
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype="float32")
    sd.wait()
    st.success("âœ… KayÄ±t tamamlandÄ±!")

    # KaydÄ± geÃ§ici dosyaya kaydet
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        sf.write(tmp.name, audio, fs)
        temp_path = tmp.name

    # Ã–zellik Ã§Ä±karÄ±mÄ±
    features = extract_features(audio, fs)
    prediction = model.predict(features)[0]

    # Tahmini gÃ¶ster
    levels = {0: ("Calm ğŸ˜Œ", "#6fc276"), 1: ("Medium ğŸ˜", "#f4c542"), 2: ("Stress ğŸ˜£", "#e74c3c")}
    label, color = levels[prediction]

    st.markdown(f"<h2 style='color:{color};text-align:center;'>ğŸ§  Tahmin: {label}</h2>", unsafe_allow_html=True)

    # KaydÄ± Ã§al
    st.audio(temp_path, format="audio/wav")
